{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaeb982",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b821dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c085fe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install turkishnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ff18add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import spacy\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "\n",
    "from vaderSentiment import vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dbe03e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c833ae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(stopwords.words(\"turkish\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "307c97dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdrcn\\AppData\\Local\\Temp\\ipykernel_13160\\2475433900.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option(\"display.max_colwidth\", -1)\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b13413d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kdrcn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kdrcn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\kdrcn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kdrcn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b42d118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"128.turkish/restaurants_train_turkish.xml.dat\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0b00ac",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8734ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "data = pd.DataFrame({\"Text\": text.split(\"\\n\"), \"Tag\": \"Text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45acdc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_index = data[data[\"Text\"].isin([\"Positive\", \"Negative\", \"Neutral\"])].index\n",
    "data.loc[sentiment_index, \"Tag\"] = \"Sentiment\"\n",
    "data.loc[sentiment_index-1, \"Tag\"] = \"Aspect\"\n",
    "df = pd.DataFrame({\"Phrase\": data[data[\"Tag\"] == \"Text\"][\"Text\"].reset_index(drop=True), \n",
    "                   \"Aspect\": data[data[\"Tag\"] == \"Aspect\"][\"Text\"].reset_index(drop=True), \n",
    "                   \"Sentiment\": data[data[\"Tag\"] == \"Sentiment\"][\"Text\"].reset_index(drop=True)})\n",
    "df = df.drop(1385, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654f132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f70448",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44e9b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f3e78b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in train.iterrows():\n",
    "    words = TextBlob(row[\"Phrase\"]).words\n",
    "    aspect = words.index(\"T\")\n",
    "    words[aspect] = row[\"Aspect\"]\n",
    "    row[\"Phrase\"] = \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aef1f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Phrase\"] = train[\"Phrase\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "train[\"Aspect\"] = train[\"Aspect\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "\n",
    "train[\"Phrase\"] = train[\"Phrase\"].apply(lambda x: \" \".join(re.sub(\"[^\\w\\s]\", \"\", x) for x in x.split()))\n",
    "train[\"Aspect\"] = train[\"Aspect\"].apply(lambda x: \" \".join(re.sub(\"[^\\w\\s]\", \"\", x) for x in x.split()))\n",
    "\n",
    "train[\"Phrase\"] = train[\"Phrase\"].apply(lambda x: \" \".join(re.sub(\"\\d\", \"\", x) for x in x.split()))\n",
    "train[\"Aspect\"] = train[\"Aspect\"].apply(lambda x: \" \".join(re.sub(\"\\d\", \"\", x) for x in x.split()))\n",
    "\n",
    "train[\"Phrase\"] = train[\"Phrase\"].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n",
    "\n",
    "# train[\"Phrase\"] = train[\"Phrase\"].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9729c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d3c7ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de7506a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"turkish\")\n",
    "stop_words.extend([\"bir\", \"icin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6ff1e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation)\n",
    "train_pos = train[train[\"Sentiment\"] == \"Positive\"]\n",
    "token_list = []\n",
    "for index, row in train_pos.iterrows():\n",
    "    text = \"\".join(x for x in train_pos[\"Phrase\"][index] if x not in  exclude and x != \"’\")\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [tok.lower() for tok in tokens if tok not in stop_words]\n",
    "    token_list.extend(tokens)\n",
    "    \n",
    "frequencies = Counter(token_list)\n",
    "frequencies_sorted = sorted(frequencies.items(), key=lambda x: x[1], reverse=True)\n",
    "top_15 = dict(frequencies_sorted[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05b9871a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'güzel': 133,\n",
       " 'mekan': 107,\n",
       " 'iyi': 82,\n",
       " 'lezzetli': 64,\n",
       " 'cok': 56,\n",
       " 'servis': 50,\n",
       " 'yemekler': 50,\n",
       " 'manzara': 41,\n",
       " 'var': 40,\n",
       " 'guzel': 39,\n",
       " 'yer': 39,\n",
       " 'uygun': 38,\n",
       " 'yemekleri': 36,\n",
       " 'kadar': 34,\n",
       " 'olarak': 34}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b57f0100",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation)\n",
    "train_neg = train[train[\"Sentiment\"] == \"Negative\"]\n",
    "token_list = []\n",
    "for index, row in train_neg.iterrows():\n",
    "    text = \"\".join(x for x in train_neg[\"Phrase\"][index] if x not in  exclude and x != \"’\")\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [tok.lower() for tok in tokens if tok not in stop_words]\n",
    "    token_list.extend(tokens)\n",
    "    \n",
    "frequencies = Counter(token_list)\n",
    "frequencies_sorted = sorted(frequencies.items(), key=lambda x: x[1], reverse=True)\n",
    "top_15 = dict(frequencies_sorted[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03d106d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'servis': 65,\n",
       " 'yer': 49,\n",
       " 'mekan': 43,\n",
       " 'yok': 40,\n",
       " 'degil': 39,\n",
       " 'kadar': 37,\n",
       " 'güzel': 35,\n",
       " 'cok': 34,\n",
       " 'yemek': 26,\n",
       " 'manzara': 25,\n",
       " 'iyi': 24,\n",
       " 'biraz': 24,\n",
       " 'var': 23,\n",
       " 'kötü': 22,\n",
       " 'fazla': 20}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d809455d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
